{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "from resnet_utils import *\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training images: 29754\nAmount of testing images: 6376\nAmount of validation images: 6376\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "class TFRecordExtractor:\n",
    "\tdef __init__(self, tfrecord_file):\n",
    "\t\tself.tfrecord_file = os.path.abspath(tfrecord_file)\n",
    "\t\n",
    "\t# def extract_fn(self, data_record):\n",
    "    \t# features = {\n",
    "     #    \t# Extract features using the keys set during creation\n",
    "     #    \t'int_list1': tf.FixedLenFeature([], tf.int64),\n",
    "     #    \t'float_list1': tf.FixedLenFeature([], tf.float32),\n",
    "     #    \t'str_list1': tf.FixedLenFeature([], tf.string),\n",
    "     #    \t# If size is different of different records, use VarLenFeature \n",
    "     #    \t'float_list2': tf.VarLenFeature(tf.float32)\n",
    "    \t# }\n",
    "    \t# sample = tf.parse_single_example(, features)\n",
    "    \t# return sample\n",
    "\t\n",
    "\t\n",
    "\tdef extract_fn(self, data_record):\n",
    "\t\tfeatures = {\n",
    "\t\t\t'int_list1': tf.FixedLenFeature([], tf.int64),\n",
    "\t\t\t'float_list1': tf.FixedLenFeature([], tf.float32),\n",
    "\t\t\t'str_list1': tf.FixedLenFeature([], tf.string),\n",
    "\t\t\t'float_list2': tf.VarLenFeature(tf.float32)\n",
    "\t\t}\n",
    "\t\tsample = tf.parse_single_example(data_record, features)\n",
    "\t\treturn sample\n",
    "\t\t\n",
    "\t# def extract_fn(self, tfrecord):\n",
    "\t# \t# Extract features using the keys\n",
    "\t# \tfeatures = {\n",
    "     #        'train/image': tf.FixedLenFeature([], tf.string),\n",
    "     #        'train/label': tf.FixedLenFeature([], tf.int64)\n",
    "     #    }\n",
    "\t# \t\n",
    "\t# \t# Extract the data record\n",
    "\t# \tsample = tf.parse_single_example(tfrecord, features)\n",
    "\t# \timage = tf.image.decode_image(sample['train/image'])\n",
    "\t# \timg_shape = (64, 64, 3)\n",
    "\t# \tlabel = sample['train/label']\n",
    "\t# \treturn [image, label, img_shape]\n",
    "\t\n",
    "\t\n",
    "\tdef extract_image(self):\n",
    "\t\tfolder_path = './ExtractedImages'\n",
    "\t\tshutil.rmtree(folder_path, ignore_errors=True)\n",
    "\t\tos.mkdir(folder_path)\n",
    "\t\t\n",
    "\t\t# Pipeline\n",
    "\t\tdataset = tf.data.TFRecordDataset([self.tfrecord_file])\n",
    "\t\tdataset = dataset.map(self.extract_fn)\n",
    "\t\titerator = dataset.make_one_shot_iterator()\n",
    "\t\tnext_image = iterator.get_next()\n",
    "\t\t\n",
    "\t\twith tf.Session() as sess:\n",
    "\t\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\t\ttry:\n",
    "\t\t\t\t# Keep extracting until tfrecord's end\n",
    "\t\t\t\twhile True:\n",
    "\t\t\t\t\timage_data = sess.run(next_image)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# compare image shape, should be the same\n",
    "\t\t\t\t\tif not np.array_equal(image_data[0].shape, (64, 64, 3)):\n",
    "\t\t\t\t\t\tprint('Image {} not decoded properly'.format(image_data[2]))\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tsave_path = os.path.abspath(os.path.join(folder_path, image_data[1].decode('utf-8')))\n",
    "\t\t\t\t\tmpimg.imsave(save_path, image_data[0])\n",
    "\t\t\t\t\tprint('Save path = ', save_path, ', label = ', image_data[2])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\t\n",
    "data_path_train = os.path.abspath('./TFRecord/kanji_train.tfrecord')\n",
    "train_nimg = 0\n",
    "for record in tf.python_io.tf_record_iterator(data_path_train):\n",
    "\t\ttrain_nimg += 1\n",
    "data_path_test = os.path.abspath('./TFRecord/kanji_test.tfrecord')\n",
    "test_nimg = 0\n",
    "for record in tf.python_io.tf_record_iterator(data_path_test):\n",
    "\t\ttest_nimg += 1\n",
    "data_path_val = os.path.abspath('./TFRecord/kanji_val.tfrecord')\n",
    "val_nimg = 0\n",
    "for record in tf.python_io.tf_record_iterator(data_path_test):\n",
    "\t\t\tval_nimg += 1\n",
    "\n",
    "# Initialize all tfrecord paths\n",
    "\n",
    "print(\"Amount of training images: \" + str(train_nimg))\n",
    "print(\"Amount of testing images: \" + str(test_nimg))\n",
    "print(\"Amount of validation images: \" + str(val_nimg))\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(data_path_train)\n",
    "test_dataset = tf.data.TFRecordDataset(data_path_test)\n",
    "val_dataset = tf.data.TFRecordDataset(data_path_val)\n",
    "\n",
    "train = TFRecordExtractor(data_path_train)\n",
    "train.extract_image()\n",
    "test = TFRecordExtractor(data_path_test)\n",
    "test.extract_image()\n",
    "val = TFRecordExtractor(data_path_val)\n",
    "val.extract_image()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
